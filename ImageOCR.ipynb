{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook provides a synopsis of how I approached a recent problem that my employer was faced with. They had thousands of individual scanned aerial images  that in the future would be turned into larger mosaiced images. A main problem was that the naming convention that was used when these aerial images were scanned and created was not useful for future use. Each aerial image had information printed on the image that was related to the specific planned flight project, the roll of film number from the project and the image number from the roll of film. Being able to rename each image file using this information would make it much easier to store, search and ultimately to mosaic and orthorectify these images into landscape scenes. The initial prospect was to open each file, read the text on the image and then rename the file. I proposed at least looking into using optical character recognition as a way to automate a time consuming and mundane task. The following notebook provides steps on how I went about performing this task. \n",
    "\n",
    "\n",
    "Before you can use this repository locally you must first install tesseract a stand alone application.  \n",
    "The notebook in this repository uses tesseract 5.0.0 Alpha version. Using other versions will likely result in different and  \n",
    "poorer text predictions that those presented in the notebooks in this repository.\n",
    "For [Windows](https://github.com/UB-Mannheim/tesseract/wiki) installation of tesseract for [Linx/Ubuntu](https://github.com/tesseract-ocr/tesseract/wiki#ubuntu-ppa) and [Mac](https://github.com/tesseract-ocr/tesseract/wiki#macos)\n",
    " \n",
    "Once tesseract is installed if you have an Anaconda installation you can use the Anconda Prompt to install all of the python libraries and their dependencies.  \n",
    "In the Anaconda Prompt change directories so that you are in the local copy of this repository. In the prompt then enter:\n",
    "\n",
    "*conda env create*  \n",
    "once the environment is created enter:  \n",
    "*conda activate imageOCR*  \n",
    "then enter:  \n",
    "*jupyter notebook*\n",
    "\n",
    "From here open the notebook entitled *ImageOCR.ipynb*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages we will use\n",
    "The primary packages that we will use are [PIL](https://pypi.org/project/Pillow/) an image processing library.  \n",
    "[Pytesseract](https://pypi.org/project/pytesseract/) a python wrapper for the installation of tesseract which we use to read the text on the image.  \n",
    "Lastly, [Matplotlib](https://matplotlib.org/) to display the images after performing cropping and covolutions.\n",
    "\n",
    "The GitHub repository where this notebook is stored contains a requirements.txt file which can be used with Conda  \n",
    "to create a virtual environment with all of the required and dependent Python packages to run this notebook. \n",
    "\n",
    "# Importing and other requirements \n",
    "Now we'll import our packages and take care of some other potential issues that will help to be able to use this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import (\n",
    "    Image,\n",
    "    ImageFilter,\n",
    "    ImageOps\n",
    ")\n",
    "from helperFunctions import checkTesseractPath\n",
    "\n",
    "import pytesseract\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "#import zipfile\n",
    "#import sys\n",
    "\n",
    "\n",
    "# a function that can be found in the readTextOnPhoto.py to help check and see if path to tesseract is set so pytesseract can use it\n",
    "checkTesseractPath() \n",
    "\n",
    "#################\n",
    "# in the event you recieve a message that you must set the path to tesseract\n",
    "# find the path to tesseract.exe uncomment the line below and re-run this cell\n",
    "#pytesseract.pytesseract.tesseract_cmd = \n",
    "##################\n",
    "\n",
    "# The image that we are looking at isn't that large. But setting the MAX IMAGE PIXELS ensures we don't have any unecessary memory issues. \n",
    "Image.MAX_IMAGE_PIXELS = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DRY (Don't Repeat Yourself)\n",
    "This is a bit of an aside but a best practice in writing code and software development is to *__don't repeat yourself__* (DRY).  \n",
    "Throught this notebook we will want to display the images. We'll use a call to matplotlib *__.imshow()__*\n",
    "to display the images frequently throughout this notebook.  \n",
    "Let's wrap it up into a function for continued use with less repitition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayImage(image, figureTitle): # our function arguments are an input image, and title for restulting figure \n",
    "    plt.imshow(image, cmap='gray') # we set the keyword argument \"cmap\", which is the colormapping of our image to grayscale\n",
    "    plt.axis('off') # axes are not helpful in this instance\n",
    "    plt.title(figureTitle) # we'll use the title to remind us of any processing we did to our image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at our first image\n",
    "Let's load a single image to see what we are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file =  os.path.join(os.getcwd(), 'images', 'singleImage', '0F6185_0001_2.tif')\n",
    "img = Image.open(file)\n",
    "\n",
    "displayImage(img, 'Aerial Image') # our first call to our newly defined function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there is information printed in the top of the image.\n",
    "\n",
    "For the sake of the size of this GitHub repository's size I have taken the liberty to pre crop all the rest of the images we will be working with.  \n",
    "If you're interested in learning about cropping the call to the PIL library is [*.crop()*](https://pillow.readthedocs.io/en/stable/reference/Image.html?highlight=crop#PIL.Image.Image.crop) where the only argument is a tuple with the dimensions *(left, upper, right, lower)* of the part image you wish to retain.  \n",
    "\n",
    "Let's load this pre cropped image to look at the information in the top right of the fullsize image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file =  os.path.join(os.getcwd(), 'images', 'croppedImages', '0F6185_0001_clipped.tif')\n",
    "#file = r'images\\croppedImages\\0F6185_0001_clipped.tif'\n",
    "img = Image.open(file)\n",
    "\n",
    "displayImage(img, 'Cropped Aerial Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the image there are a mix of characters, numbers and symbols. This is the information we want to use to rename this image.  \n",
    "\n",
    "*__DWW-A__:* is the project  \n",
    "\n",
    "*__5__:* is the roll of film on this aeral images flight line  \n",
    "\n",
    "*__1__:* is the picture number on the film roll.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What would happen if we try and read this text directly off this image?\n",
    "\n",
    "We'll give it a try but first let's take a look at some of the keyword arguments that we use in our call to  \n",
    "*__pytesseract.image_to_string()__* in the next code block\n",
    "\n",
    "Tesseract has different configurations that can be used when trying to read text.  \n",
    "\n",
    "Here the keyword argument \"__lang__\" is set to english.  \n",
    "\n",
    "In our \"__config__\" argument we use *--psm 7*. This argument stands for *page segmentation mode.*\\\n",
    "Looking at the tesseract [documentation](https://github.com/tesseract-ocr/tesseract/blob/master/doc/tesseract.1.asc) we can see that using __7__ will treat the image as a single line of text.  \n",
    "\n",
    "The last argument \"__tessedit_char_whitelist__\" allows control over the characters that tesseract is allowed to consider when reading text on a image.  \n",
    "Here the argument is set to allow for all numbers and all capitalized letters as well as a hyphen symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pytesseract.image_to_string(\n",
    "    img, \n",
    "    lang='eng',\n",
    "    config='--psm 7 -c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before printing the text read by the call to tesseract we will remove any carriage returns and strip white space  from the text read on the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.strip('\\n')\n",
    "text = text.strip()\n",
    "print('The text on the image is being read as:', text)\n",
    "\n",
    "displayImage(img, 'Cropped Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that these results are not very satisfactory.  \n",
    "Only three characters were detected and none of them are in this image.\n",
    "\n",
    "Let's try and invert the image and see if that helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ImageOps.invert(img)\n",
    "\n",
    "displayImage(img, 'Inverted Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if inverting the image will improve tesseract's ability to read the text on this image.  \n",
    "\n",
    "\n",
    "### More DRY\n",
    "We will continue to use the same lines of code related to reading and printing the text on the image. Let's wrap this code in a function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTextAndPrint(image):\n",
    "    text = pytesseract.image_to_string(\n",
    "        image,\n",
    "        lang='eng',\n",
    "        config='--psm 7 -c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ-')\n",
    "    \n",
    "    text = text.strip('\\n')\n",
    "    text = text.strip()\n",
    "    print('The text on the image is being read as:', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see inverting the image made reading the text any easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readTextAndPrint(img) # the first call to our read text function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can see that these results are not very satisfactory. This time we only predicted \n",
    "2 characters and again neither of them is in this image.  \n",
    "\n",
    "## Image Convolution \n",
    "\n",
    "Let's implement some image processing steps to isolate the text on the image and make all other pixels in the image white.  \n",
    "First we will get the dimensions of our cropped image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageWidth, imageHeight = img.size\n",
    "print ('Our Image is', imageWidth, 'x', imageHeight, 'pixels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will use the PIL *__.load()__* function. As stated in the PIL documentation when using the __Image.open()__ function:\\\n",
    "*This is a lazy operation; this function identifies the file, but the file remains open and the\\\n",
    "actual image data is not read from the file until you try to process the data (or call the load() method)*  \n",
    "Making the call to *__.load__* and setting it to *imagePixel* allows us access to the underlying pixels in the image.  \n",
    "We will still refer to img when displaying. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePixels = img.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our image is being displayed in 8-bit gray scale, so any pixel value in our image could have a value between 0-255.  \n",
    "Now we will nest two for loops to go through each pixel in our image and determine if a pixel is greater than value of 40.  \n",
    "If a pixels is greater than 40 it will be set to a pixel value of 255 which in this grayscale is equivalent to white.  \n",
    "Pixels values that are less than 40 will retain their current value. I chose this value of 40 through previous experimentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " for y in range(0, imageHeight):\n",
    "    for x in range(0, imageWidth):\n",
    "        if imagePixels[x, y] > 40:\n",
    "            imagePixels[x, y] = 255\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "displayImage(img, 'Proecessed Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That process signficantly cleaned up the back ground and helped to isoltate the text. \n",
    "Now lets try reading the text on this cleaned up image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readTextAndPrint(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUCCESS!!!\n",
    "Through these process steps we were able to use tesseract to correctly read the text on this image. \n",
    "\n",
    "I know from experience with other images that setting low pixel values to zero or black in this  \n",
    "grayscale can help to thicken the text in the image and improve the ability of tesseract to correctly read the text. \n",
    "\n",
    "In this next code block we will go through each pixel as before and set those that are less than or equal to 11 in 8 bit range to 0.  \n",
    "Again I picked the value 11 through previous experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in range(0, imageHeight):\n",
    "    for x in range(0, imageWidth):\n",
    "        if imagePixels[x, y] <= 11:\n",
    "            imagePixels[x, y] = 0\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "displayImage(img, 'Proecessed Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This last image convolution doesn't buy us much in this instance, but it can and will be helpful \n",
    "with reading text on other images. \n",
    "\n",
    "Let's try one more method to thicken the text on our image. \n",
    "Next, we will call the ImageFilter.MinFilter() back to back.  \n",
    "MinFilter performs a moving window over the entire image where the *__size__* argument \n",
    "is the size of the window in pixels  \n",
    "and the lowest pixel value in the window is returned to pixel in the center of the window. I was not able to find in the PIL [documentation](https://pillow.readthedocs.io/en/5.2.x/reference/ImageFilter.html)  \n",
    "what the maximum size value is but a size of 5 was the largest that I could use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.filter(ImageFilter.MinFilter(size=3))\n",
    "img = img.filter(ImageFilter.MinFilter(size=5))\n",
    "\n",
    "displayImage(img, 'Minimum Filtered Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Function \n",
    "We'll make one last function as we'll be looping through a bunch of pre-cropped images to see how succesfully  \n",
    "we can read the text on different scanned aerial images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageConvolution(file):\n",
    "    img = Image.open(file)\n",
    "    img = ImageOps.invert(img)\n",
    "    imageWidth, imageHeight = img.size\n",
    "    imagePixels = img.load()\n",
    "    \n",
    "    for y in range(0, imageHeight):\n",
    "        for x in range(0, imageWidth):\n",
    "            if imagePixels[x, y] > 40:\n",
    "                imagePixels[x, y] = 255\n",
    "            else:\n",
    "                pass\n",
    "    \n",
    "    for y in range(0, imageHeight):\n",
    "        for x in range(0, imageWidth):\n",
    "            if imagePixels[x, y] <= 11:\n",
    "                imagePixels[x, y] = 0\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "    img = img.filter(ImageFilter.MinFilter(size=3))\n",
    "    img = img.filter(ImageFilter.MinFilter(size=5))\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globPath = os.path.join(os.getcwd(), 'images', 'croppedImages', '*.tif')\n",
    "files = glob.glob(globPath)\n",
    "files.sort()\n",
    "\n",
    "# here we use a for loop to process each cropped image and read the text on it\n",
    "# using the previously defined functions\n",
    "for file in files:\n",
    "    processedImage = imageConvolution(file)\n",
    "    readTextAndPrint(processedImage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "As we can see from these results, we were approximately 60% accurate in reading the text that was printed on each image.  \n",
    "The accuracy of this method was not as high as I would have liked but we did use this method in conjunction with some other techniques to rename many files.  \n",
    "Ultimately the center that was scanning these aerial images switched their naming convention to be more in line with the convention that we were trying to use.  \n",
    "Subsequently these optical character recognition efforts were no longer needed.\n",
    "\n",
    "\n",
    "#### Futher Exploration\n",
    "You can look at *ImageOCR_Part2* for a further exploration of why some of the images such as image 8 or 15 were not read properly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
